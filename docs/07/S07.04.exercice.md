# Exercice


## activer Kubernetes dans Docker Desktop

1. Open Docker Desktop
2. Go to Settings > Kubernetes
3. Check "Enable Kubernetes"
4. Click "Apply & Restart"

Ça devrait prendre quelques minutes.

Pour vérifier l'installation :

```bash
kubectl version --output=yaml
```

ce qui retourne quelque chose comme:

```yaml
clientVersion:
  buildDate: "2022-11-09T13:36:36Z"
  compiler: gc
  gitCommit: 872a965c6c6526caa949f0c6ac028ef7aff3fb78
  gitTreeState: clean
  gitVersion: v1.25.4
  goVersion: go1.19.3
  major: "1"
  minor: "25"
  platform: darwin/amd64
kustomizeVersion: v4.5.7
serverVersion:
  buildDate: "2022-11-09T13:29:58Z"
  compiler: gc
  gitCommit: 872a965c6c6526caa949f0c6ac028ef7aff3fb78
  gitTreeState: clean
  gitVersion: v1.25.4
  goVersion: go1.19.3
  major: "1"
  minor: "25"
  platform: linux/amd64
```

et pour lister les nodes

```bash
kubectl get nodes
```

retourne

```bash
NAME             STATUS   ROLES           AGE     VERSION
docker-desktop   Ready    control-plane   3h55m   v1.25.4
```

A ce stade vous devez avoir une  multitude de  containers sur votre machine

la commande `docker ps` retourne pas moins de 18 containers sur mon ordi!

Et un certain nombre de pods par defaut :

```bash
kubectl get pods -A
```

retourne

```bash
NAMESPACE     NAME                                     READY   STATUS    RESTARTS        AGE
kube-system   coredns-565d847f94-4lbzs                 1/1     Running   0               5h58m
kube-system   coredns-565d847f94-bzq7n                 1/1     Running   0               5h58m
kube-system   etcd-docker-desktop                      1/1     Running   0               5h58m
kube-system   kube-apiserver-docker-desktop            1/1     Running   0               5h58m
kube-system   kube-controller-manager-docker-desktop   1/1     Running   0               5h58m
kube-system   kube-proxy-2c7jz                         1/1     Running   0               5h58m
kube-system   kube-scheduler-docker-desktop            1/1     Running   0               5h58m
kube-system   storage-provisioner                      1/1     Running   0               5h58m
kube-system   vpnkit-controller                        1/1     Running   28 (9m6s ago)   5h58m
```

Lorsqu'on active Kubernetes dans Docker Desktop, plusieurs composants sont lancés pour supporter le cluster Kubernetes local, ce qui peut effectivement augmenter le nombre de conteneurs. Ce nombre élevé de conteneurs est dû au fait que Kubernetes lui-même est composé de divers services critiques, chacun fonctionnant généralement dans son propre conteneur. Les conteneurs par défaut peuvent inclure :

- **`etcd`** : Le key value store utilisé comme stockage principal de Kubernetes pour toutes les données du cluster.
- **`kube-apiserver`** : Le serveur API de Kubernetes qui gère l'API Kubernetes.
- **`kube-scheduler`** : Responsable de l'ordonnancement des charges de travail (pods) sur les nœuds appropriés.
- **`kube-controller-manager`** : Gère les différents contrôleurs dans Kubernetes, en s'assurant que l'état souhaité du cluster correspond à l'état actuel.
- **`kube-proxy`** : Maintient les règles réseau sur chaque nœud, en gérant la communication vers les pods.
- **`kube-dns`** (coredns) : Fournit des services DNS pour le cluster afin de permettre la découverte de services.
- **`kubelet`** : Agent qui s'exécute sur chaque nœud et communique avec le serveur API de Kubernetes pour exécuter des tâches sur le nœud.
- **Ingress Controller** : Parfois activé par défaut pour gérer l'accès externe aux services.
- **Container Network Interface (CNI)** : Plugins réseau comme Flannel, Calico, ou d'autres pour fournir la connectivité réseau entre les pods.
- **Storage Provisioner** : Pour provisionner automatiquement du stockage persistant lorsqu'un PersistentVolumeClaim (PVC) est créé.
- **Metrics Server** : Utilisé pour collecter des métriques de ressources comme le CPU et la mémoire, utile pour l'autoscaling.



## Création d'un pod

Dans un fichier  `hello-pod.yaml`, écrire

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: hello-pod
spec:
  containers:
  - name: hello-container
    image: nginx:latest
    ports:
    - containerPort: 80
```

Pour activer le pod, le lancer avec la commande `apply` (on applique une configuration)


```bash
kubectl apply -f hello-pod.yaml
```

```bash
kubectl get pods
```

donne

```bash
NAME        READY   STATUS    RESTARTS   AGE
hello-pod   1/1     Running   0          13m
```

Puis pour ???

```bash
kubectl port-forward hello-pod 8080:80
```

Vérifiez que le pod tourne en allant à  `http://localhost:8080`. Vous devez y voir la page d'accueil de Nginx


### Le fichier pod.yaml

Revenons sur le fichier de configuration du pod.

Let me break down each component of the Pod YAML file and explain its purpose and significance.

- `apiVersion: v1`: la version stable de l'API kubernetes

- `kind: Pod`: déclare le type de ressource. ici c'est un `pod`
- `metadata:` le nom du pod qui est son identifiant unique. On pourrait  rajouter `labels` ou `annotations`

```yaml
    metadata:
        name: hello-pod
```

- `spec:` defini l'état final et désiré du pod et donc la configuration de ce qui doit tourner.

- `containers:` la liste des containers contenu dans ce pod. Il pourrait y en avoir plusieurs. ici il n'y en a qu'un seul

 ```yaml
   containers:
   - name: hello-container
     image: nginx:latest
     ports:
     - containerPort: 80
 ```

A chaque container on spécifie pour débuter simplement:

- `name: hello-container`: un nom unique
  - `image: nginx:latest`: L'image docker a utiliser
  - `ports:`:
    - `containerPort: 80`: le port qu'utilise Nginx interne au container (non exposé)

On pourrait ajouter plus de précisions:

- Resource limits (CPU/memory)
- Environment variables
- Volume mounts
- Readiness/liveness probes


Voici par exemple une configuration pour un pod de production

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: hello-pod
  labels:
    app: hello-app
    environment: production
  annotations:
    description: "Production web server pod"
    contact: "team-frontend@company.com"
spec:
  containers:
  - name: hello-container
    image: nginx:1.25.3  # Specific version instead of 'latest'
    ports:
    - containerPort: 80
      name: http  # Named port for better readability
    resources:
      requests:
        memory: "128Mi"
        cpu: "100m"
      limits:
        memory: "256Mi"
        cpu: "500m"
    livenessProbe:
      httpGet:
        path: /
        port: http
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 5
      failureThreshold: 3
    readinessProbe:
      httpGet:
        path: /
        port: http
      initialDelaySeconds: 5
      periodSeconds: 5
    startupProbe:
      httpGet:
        path: /
        port: http
      failureThreshold: 30
      periodSeconds: 10
    env:
    - name: NGINX_HOST
      value: "example.com"
    - name: POD_NAME
      valueFrom:
        fieldRef:
          fieldPath: metadata.name
    volumeMounts:
    - name: nginx-config
      mountPath: /etc/nginx/conf.d
    - name: static-content
      mountPath: /usr/share/nginx/html
    securityContext:
      runAsNonRoot: true
      runAsUser: 101  # nginx user
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
  volumes:
  - name: nginx-config
    configMap:
      name: nginx-config
  - name: static-content
    emptyDir: {}
  terminationGracePeriodSeconds: 60
```

On a

- des Metadata plus complètes
- des limites aux resources que le pod peut utiliser
  - 100m CPU = 0.1 CPU core
  - Mi = Mebibytes (1Mi = 1.048576 MB)
- des healthcheck: notez la granularité assez précise
  - livenessProbe:  # Checks if container is alive
  - readinessProbe: # Checks if container is ready to serve traffic
  - startupProbe:   # Gives container time to startup

et pour chaque probe on definit

- `initialDelaySeconds`: Wait before first check
- `periodSeconds`: How often to check
- `timeoutSeconds`: How long to wait for response
- `failureThreshold`: How many failures before taking action

on a aussi

- les variables d'environnement: valeurs explicites (cf `NGINX_HOST`) ou référencées (cf `POD_NAME` et `fieldPath: metadata.name`)
- la gestion des volumes
- un contrôle de sécurité:
  - Enforces security best practices
  - Runs container as non-root user
  - Removes unnecessary Linux capabilities
  - Prevents privilege escalation

- Enfin un *graceful shutdown*: `terminationGracePeriodSeconds: 60` qui donne un temps au container avant d'être terminé.

## Commandes de base `kubectl`

### Inspecter les pods

- **Lister les pods** : `kubectl get pods`   ou  plus détaillé :  `kubectl get pods -o wide` et le flag `-w` pour voir les changements en temps réel `kubectl get pods -w`
- Détails d'un pod : `kubectl describe pod hello-pod`      # Shows events, conditions, volumes, etc.
- Les logs : `kubectl logs hello-pod`, avec le flag `-f` en temps reel: `kubectl logs -f hello-pod`


Par exemple, `kubectl describe pod` donne toute les informations

```bash
Name:             hello-pod
Namespace:        default
Priority:         0
Service Account:  default
Node:             docker-desktop/192.168.65.4
Start Time:       Tue, 05 Nov 2024 13:30:58 +0100
Labels:           <none>
Annotations:      <none>
Status:           Running
IP:               10.1.0.6
IPs:
  IP:  10.1.0.6
Containers:
  hello-container:
    Container ID:   docker://cfd41774c878f0d33b4752358e3060dbc72f537d33ee62263ccc7a3d9043d5fe
    Image:          nginx
    Image ID:       docker-pullable://nginx@sha256:28402db69fec7c17e179ea87882667f1e054391138f77ffaf0c3eb388efc3ffb
    Port:           80/TCP
    Host Port:      0/TCP
    State:          Running
      Started:      Tue, 05 Nov 2024 13:31:40 +0100
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-9zwln (ro)
Conditions:
  Type              Status
  Initialized       True
  Ready             True
  ContainersReady   True
  PodScheduled      True
Volumes:
  kube-api-access-9zwln:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age   From               Message
  ----    ------     ----  ----               -------
  Normal  Scheduled  43m   default-scheduler  Successfully assigned default/hello-pod to docker-desktop
  Normal  Pulling    43m   kubelet            Pulling image "nginx"
  Normal  Pulled     43m   kubelet            Successfully pulled image "nginx" in 40.860259142s
  Normal  Created    43m   kubelet            Created container hello-container
  Normal  Started    43m   kubelet            Started container hello-container
```

### debugging

- Executer des commandes dans le container `kubectl exec -it hello-pod -- /bin/bash`  (interactive shell)
- copier des fichiers:  du pod au local : `kubectl cp hello-pod:/etc/nginx/nginx.conf ./nginx.conf` ou du local au pod:  `kubectl cp ./config.txt hello-pod:/tmp/`
- port forwarding: `kubectl port-forward hello-pod 8080:80`  du port 8080 Local  au port 80 du pod

### management des ressources

Suppression:

- `kubectl delete pod hello-pod`               # Delete specific pod
- `kubectl delete -f hello-pod.yaml`           # Delete using config file
- `kubectl delete pods --all`                  # Delete all pods in current namespace

Mise a jour:

- `kubectl apply -f hello-pod.yaml`            # Apply changes from file
- `kubectl edit pod hello-pod`                 # Edit pod configuration directly

### La documentation

est disponible via `kubectl`:

- `kubectl explain pods`
- `kubectl explain pod.spec`
- `kubectl explain pod.spec.containers`

etc ...

## Partie 2: Deployments et Services

On va maintenant créer une appli web simple mais avec 3 pods nginx


Dans un fichier  `frontend-deployment.yaml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
    spec:
      containers:
      - name: frontend
        image: nginx:latest
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: frontend-service
spec:
  type: LoadBalancer
  selector:
    app: frontend
  ports:
  - port: 80
    targetPort: 80
```

Appliquer

```bash
kubectl apply -f frontend-deployment.yaml
```

```bash
deployment.apps/frontend-deployment created
service/frontend-service created
```

Puis explorer

- on voit 3 pods: `kubectl get pods`

```bash
NAME                                  READY   STATUS    RESTARTS   AGE
frontend-deployment-bfcbdb7cc-984cm   1/1     Running   0          23s
frontend-deployment-bfcbdb7cc-lv4mp   1/1     Running   0          23s
frontend-deployment-bfcbdb7cc-xc2rm   1/1     Running   0          23s
```

- 2 services: `kubectl get services`

```bash
NAME               TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
frontend-service   LoadBalancer   10.104.40.249   localhost     80:32234/TCP   42s
kubernetes         ClusterIP      10.96.0.1       <none>        443/TCP        6h4m
```

et le déploiements: `kubectl get deployments`

```bash
NAME                  READY   UP-TO-DATE   AVAILABLE   AGE
frontend-deployment   3/3     3            3           18s
```

Et on est passé a 26 containers en cours d'execution!


### Services ?

Qu'est-ce qu'un service dans Kubernetes ?

Dans Kubernetes, un service est un objet abstrait qui expose un ou plusieurs pods pour permettre leur accès réseau, de manière stable et persistante. Les services permettent de communiquer avec les pods sans se soucier de leur adresse IP exacte, qui peut changer si un pod est recréé ou redéployé.

En d'autres termes, un service agit comme un point d'accès fixe pour accéder à des applications déployées dans des pods.
Types de services courants

Voici les principaux types de services que l'on peut voir dans un cluster Kubernetes :

- ClusterIP : Expose le service à l'intérieur du cluster uniquement, en assignant une adresse IP interne. C'est le type par défaut. Les autres pods du cluster peuvent accéder au service, mais il n'est pas accessible depuis l'extérieur.

- NodePort : Expose le service sur un port spécifique de chaque nœud du cluster. On peut y accéder de l'extérieur en utilisant l'adresse IP du nœud et le port spécifié.

- LoadBalancer : Crée un service accessible de l'extérieur via un IP et un load balancer, généralement dans un environnement cloud. Le service va alors répartir le trafic entre les pods derrière lui.

- ExternalName : Associe le service à un nom DNS externe, redirigeant ainsi le trafic vers une adresse externe au cluster.


Quand on exécute kubectl get services, on obtient une liste des services actuellement définis dans le namespace actif (ou dans un namespace spécifique si précisé). Pour chaque service, on voit des informations comme :

- Name : Le nom du service.
- Type : Le type de service (ClusterIP, NodePort, LoadBalancer, etc.).
- Cluster-IP : L'adresse IP interne attribuée au service pour l'accès dans le cluster.
- External-IP : L'IP externe si le service est exposé à l'extérieur (pour un type LoadBalancer, par exemple).
- Ports : Les ports utilisés par le service.
- Age : L'âge du service (depuis combien de temps il existe).

### Deployment ?

Un deployment est un objet Kubernetes qui gère le déploiement et la mise à jour des applications. Il définit l'état souhaité pour une application, comme le nombre de pods à exécuter, l'image du conteneur à utiliser, et d'autres paramètres de configuration. Kubernetes utilise ce deployment pour créer et gérer les pods qui contiennent les conteneurs de l'application, et pour s'assurer que l'état réel correspond à l'état souhaité.

En d'autres termes, un deployment facilite la gestion du cycle de vie des applications dans Kubernetes. Il permet de déployer des applications, d'en faire la mise à jour, et d'assurer leur disponibilité, tout en permettant le scaling automatique et le rollback (retour en arrière en cas de problème).
Que voit-on avec kubectl get deployments ?

Quand on exécute kubectl get deployments, on obtient une liste des deployments définis dans le namespace actif (ou dans un namespace spécifique si précisé). Pour chaque deployment, on voit des informations comme :

- Name : Le nom du deployment.
- Ready : Le nombre de pods disponibles sur le nombre de pods désirés (par exemple, 3/3).
- Up-to-date : Le nombre de pods qui sont à jour avec la configuration spécifiée.
- Available : Le nombre de pods qui sont en bon état et disponibles pour gérer du trafic.
- Age : L'âge du deployment (depuis combien de temps il existe).

Pourquoi utiliser un deployment ?

Un deployment permet de :

- Déployer des applications de manière déclarative en spécifiant l'état souhaité.
- Faire du scaling facilement en augmentant ou en réduisant le nombre de pods.
- Effectuer des mises à jour progressives (rolling updates) sans interruption de service.
- Faire un rollback (retour en arrière) si une mise à jour pose des problèmes.

En résumé, un deployment est un contrôleur qui assure que l'application tourne correctement et est capable de gérer le cycle de vie de cette application dans Kubernetes.


## Part 3: Multi-Component Application

Ce manifest YAML déploie une application full-stack avec un frontend et un backend, chacun ayant un deployment et un service associé.


Voici un exemple de manifest

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 2
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
    spec:
      containers:
      - name: frontend
        image: nginx:latest
        ports:
        - containerPort: 80
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend-api
spec:
  replicas: 2
  selector:
    matchLabels:
      app: backend-api
  template:
    metadata:
      labels:
        app: backend-api
    spec:
      containers:
      - name: backend
        image: node:alpine
        ports:
        - containerPort: 3000
---
apiVersion: v1
kind: Service
metadata:
  name: frontend-service
spec:
  type: LoadBalancer
  selector:
    app: frontend
  ports:
  - port: 80
---
apiVersion: v1
kind: Service
metadata:
  name: backend-service
spec:
  selector:
    app: backend-api
  ports:
  - port: 3000
```


Dans la partie deploiement front end

- apiVersion: apps/v1 – La version de l'API Kubernetes utilisée pour le déploiement.
- kind: Deployment – Indique qu'il s'agit d'un deployment, qui gère le déploiement et la mise à jour de l'application.
- metadata:
  - name: frontend – Le nom du deployment, ici "frontend".
- spec: La spécification du deployment.
  - replicas: 2 – Nombre de pods souhaités pour ce deployment. Ici, on demande deux réplicas pour le frontend.
  - selector:
    - matchLabels: app: frontend – Critère de sélection pour associer ce deployment aux pods avec le label app: frontend.
    - template: Modèle utilisé pour créer les pods.
      - metadata:
        - labels: app: frontend – Label associé aux pods créés par ce deployment.
        - spec:
          - containers: Liste des conteneurs dans chaque pod.
            - name: frontend – Nom du conteneur.
            - image: nginx:latest – Image Docker utilisée pour ce conteneur. Ici, c'est NGINX, souvent utilisé pour le frontend.
            - ports:
              - containerPort: 80 – Port exposé par le conteneur NGINX pour le frontend.

Et dans la partie backend est similaire avec une image alpine:node (une image légère de Node.js) et des metadata dédiées


Ce manifest déploie une application en deux parties :

- Un frontend avec NGINX, exposé via un service de type LoadBalancer pour être accessible publiquement.
- Un backend avec Node.js, exposé via un service interne, accessible seulement depuis d'autres composants du cluster (car il n’a pas de type LoadBalancer).

Chaque partie (frontend et backend) a un deployment qui gère deux réplicas de l'application, assurant la haute disponibilité.

Les services permettent de connecter les utilisateurs au frontend (grâce au LoadBalancer) et d'assurer la communication entre le frontend et le backend au sein du cluster.

## Self-Healing Demo

Watch pods in real-time:

```bash
kubectl get pods -w
```

In another terminal, delete a pod:

```bash
kubectl delete pod frontend-<pod-id>
```

On observe

```bash
NAME                                  READY   STATUS    RESTARTS   AGE
frontend-deployment-bfcbdb7cc-984cm   1/1     Running   0          18m
frontend-deployment-bfcbdb7cc-lv4mp   1/1     Running   0          18m
frontend-deployment-bfcbdb7cc-xc2rm   1/1     Running   0          18m
frontend-deployment-bfcbdb7cc-984cm   1/1     Terminating   0          19m
frontend-deployment-bfcbdb7cc-v6crm   0/1     Pending       0          0s
frontend-deployment-bfcbdb7cc-v6crm   0/1     Pending       0          0s
frontend-deployment-bfcbdb7cc-v6crm   0/1     ContainerCreating   0          0s
frontend-deployment-bfcbdb7cc-984cm   0/1     Terminating         0          19m
frontend-deployment-bfcbdb7cc-984cm   0/1     Terminating         0          19m
frontend-deployment-bfcbdb7cc-984cm   0/1     Terminating         0          19m
frontend-deployment-bfcbdb7cc-v6crm   1/1     Running             0          3s
```

C'est assez cool!



Maintenant on peut aussi rajouter des pods a la volée



```bash
kubectl scale deployment frontend --replicas=5
```

On voit 2 nouveaux pods apparaître!



## Add health checks to deployments


Les health checks (vérifications de l'état de santé) sont importants pour s'assurer que Kubernetes sait si un conteneur fonctionne correctement ou non. Kubernetes propose deux types principaux de health checks :

- Liveness Probe : Vérifie si le conteneur est "vivant". Si cette vérification échoue, Kubernetes redémarre le conteneur.
- Readiness Probe : Vérifie si le conteneur est prêt à recevoir du trafic. Si cette vérification échoue, le conteneur est marqué comme "non prêt", et le service ne redirige pas de trafic vers lui.

Voici un exemple de manifest YAML pour ajouter ces probes aux déploiements frontend et backend.

Bien sûr ! Les **health checks** (vérifications de l'état de santé) sont importants pour s'assurer que Kubernetes sait si un conteneur fonctionne correctement ou non. Kubernetes propose deux types principaux de health checks :

1. **Liveness Probe** : Vérifie si le conteneur est "vivant". Si cette vérification échoue, Kubernetes redémarre le conteneur.
2. **Readiness Probe** : Vérifie si le conteneur est prêt à recevoir du trafic. Si cette vérification échoue, le conteneur est marqué comme "non prêt", et le service ne redirige pas de trafic vers lui.

Voici un exemple de manifest YAML pour ajouter ces probes aux déploiements **frontend** et **backend**.

### Exemple de manifest avec des health checks

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 2
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
    spec:
      containers:
      - name: frontend
        image: nginx:latest
        ports:
        - containerPort: 80
        livenessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 10
          periodSeconds: 5
        readinessProbe:
          httpGet:
            path: /
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend-api
spec:
  replicas: 2
  selector:
    matchLabels:
      app: backend-api
  template:
    metadata:
      labels:
        app: backend-api
    spec:
      containers:
      - name: backend
        image: node:alpine
        ports:
        - containerPort: 3000
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 10
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 10
```

### Explication des health checks

#### Frontend

Dans le cas du conteneur **frontend** (NGINX) :
- **Liveness Probe** :
  - Vérifie l'URL `http://localhost:80/`.
  - Cette probe s'assure que le serveur NGINX est toujours "vivant". Si l'URL `/` renvoie une réponse, le conteneur est considéré comme vivant.
  - `initialDelaySeconds: 10` : Attente de 10 secondes après le démarrage avant de lancer la première vérification.
  - `periodSeconds: 5` : La vérification est ensuite répétée toutes les 5 secondes.

- **Readiness Probe** :
  - Vérifie également l'URL `http://localhost:80/`.
  - Cette probe s'assure que NGINX est prêt à recevoir du trafic. Si l'URL `/` est accessible, le conteneur est marqué comme prêt.
  - `initialDelaySeconds: 5` : Attente de 5 secondes après le démarrage avant la première vérification.
  - `periodSeconds: 5` : La vérification est ensuite répétée toutes les 5 secondes.

#### Backend

Dans le cas du conteneur **backend** (Node.js) :
- **Liveness Probe** :
  - Vérifie l'URL `http://localhost:3000/health`.
  - Cette probe permet de vérifier si l'API backend est en bon état. Si le endpoint `/health` répond, le conteneur est considéré comme vivant.
  - `initialDelaySeconds: 10` : Attente de 10 secondes après le démarrage.
  - `periodSeconds: 10` : La vérification est ensuite répétée toutes les 10 secondes.

- **Readiness Probe** :
  - Vérifie aussi l'URL `http://localhost:3000/health`.
  - Cette probe s'assure que le backend est prêt à recevoir du trafic. Si le endpoint `/health` est accessible, le conteneur est marqué comme prêt.
  - `initialDelaySeconds: 5` : Attente de 5 secondes après le démarrage.
  - `periodSeconds: 10` : La vérification est ensuite répétée toutes les 10 secondes.

### Remarques

- Ces probes utilisent la méthode **httpGet** pour envoyer une requête HTTP sur un chemin spécifique. Il est possible d'utiliser également une vérification par **TCP socket** ou en **exécutant une commande** à l'intérieur du conteneur.
- Les endpoints `/` pour le frontend (NGINX) et `/health` pour le backend (Node.js) doivent être configurés pour répondre correctement afin que les probes réussissent.
- Les paramètres **initialDelaySeconds** et **periodSeconds** peuvent être ajustés en fonction du temps de démarrage de chaque conteneur et de la fréquence souhaitée des vérifications.
-

## Cleanup

```bash
kubectl delete -f full-stack.yaml
kubectl delete -f config.yaml
```