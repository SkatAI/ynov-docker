# Kubernetes

## A quoi ca sert

Kubernetes est un outil d'orchestration de containers.

img : chef d'orchestre

Kubernetes a √©t√© invent√© par Google en 2014 pour s'affranchir de la plateforme d'h√©bergement (hosting) d'une application.

Cela permet a une entreprise d'h√©berger ses services sur n'importe quel fournisseur : GCP, AWS, DO, ...

Quand :

- Docker permet de faire tourner une application **multi containers** sur n'importe quelle machine,

Alors :

- Kubernetes permet faire tourner une application d√©centralis√©e **multi-serveurs** sur n'importe quel fournisseur cloud.

> On dit que Kubernetes permet de s'abstraire de l'infrastructure d'h√©bergement (*it abstracts infrastructure*)

Kubernetes est con√ßu comme un **cluster** de machines hautement disponibles. Ces machines sont connect√©es pour travailler comme une seule. Cette **abstraction** permet de d√©ployer des applications sans penser aux machines sp√©cifiques sur lesquelles elles doivent fonctionner.

### et en plus

K8s apporte des fonctionnalit√©s importantes en plus de la gestion des containers:

- d√©ploiement z√©ro temps d'arr√™t (*zero downtime*)
- **auto scaling** en fonction de la demande
- **self-healing**: auto reparation des √©l√©ments qui plantent

Avec Kubernetes on passe d'une application

- docker : mono container
- docker compose : multi containers
- Kubernetes : multi containers sur multi serveurs / multi cloud
  - + [self healing + auto scaling + z√©ro temps d'arr√™t]

### origine du mot Kubernetes

Kubernetes vient du grecque et veut dire timonier (*helmsman*): le pilote √† la roue du bateau. D'ou le logo qui est une roue de bateau

![K8s logo](./../../img/k8s-logo.png)

K8s = Kubernetes est une evolution des outils interne √† Google de gestion des containers a grande √©chelle : Borg et Omega

![Borg et omega](./../../img/K8s-dna-borg.png)

## Quand passer de Docker √† Kubernetes ?

Il vaut mieux rester avec Docker ou docker compose lorsque l'application est relativement simple et l''√©quipe est petite:

- Le d√©ploiement est sur un seul serveur
- Pas besoin d'orchestration avanc√©e
- Les besoins en scaling sont minimes
- La complexit√© op√©rationnelle doit √™tre r√©duite

Mais Docker Compose ne sait pas fournir

- scaling automatique en fonction de la demande (load)
- d√©ploiements sans interruption: z√©ro temps d'arr√™t
- Plusieurs instances d√©ploy√©es sur plusieurs machines de fa√ßon automatique
- un failover / r√©cup√©ration automatique en cas de panne (le self healing)

Docker Compose suffit :

- Petite application web + base de donn√©es
- Environnement de d√©veloppement
- Micro-services simples (2-3 services)
- D√©ploiements sur serveur unique
- √âquipe de 1-5 d√©veloppeurs


### Passer √† Kubernetes

Kubernetes est utile quand on a besoin de

- g√©rer des applications d√©ploy√©es sur plusieurs serveurs (r√©gions)
- de load balancing/ r√©partition de charge entre les serveurs
- de gestion automatique des pannes avec r√©cup√©ration
- Un scaling automatique bas√©e sur des m√©triques
- Une utilisation efficace des ressources entre machines

et Kubernetes devient indispensable si on a besoin de

- Service discovery avanc√©e (on y revient plus loin)
- Gestion automatique des certificats SSL/TLS
- Gestion des ressources
- R√®gles de routage complexes (Ingress)
- Scheduling des containers sur plusieurs nodes


Exemple d'applications pour lesquelles Kubernetes devient n√©cessaire :

- Plateforme e-commerce avec plusieurs services
- Application globale avec d√©ploiements par r√©gion
- Applications n√©cessitant une disponibilit√© de 99,99%
- Architecture de micro-services avec 10+ services
- √âquipe de 10+ d√©veloppeurs travaillant sur diff√©rents composants

Voici un tr√®s bon article sur Kubernetes

<https://wiki.sfeir.com/kubernetes/>


## D√©ploiement sans temps mort

Pour une application typique bas√©e sur Docker, sans Kubernetes,  il faut g√©n√©ralement arr√™ter le conteneur existant et en d√©marrer un nouveau avec le code mis √† jour. Cette s√©quence stop + start peut entra√Æner un court temps d'arr√™t, l'application √©tant offline pendant la transition.

- Absence de mises √† jour progressives (*Rolling Updates*) : Docker n‚Äôa pas de support int√©gr√© pour les mises √† jour progressives. Donc, lors du d√©ploiement d‚Äôun nouveau conteneur, on remplace soit imm√©diatement l‚Äôancien conteneur (ce qui provoque un temps d'arr√™t), soit on lance un nouveau conteneur s√©par√©ment et on switch.

Kubernetes, en revanche, est con√ßu sp√©cifiquement pour g√©rer ces transitions **en douceur**:

- **Mises √† jour progressives** (*Rolling Updates*) : Kubernetes permet des mises √† jour progressives, qui remplacent progressivement les anciennes instances de l‚Äôapplication par les nouvelles. Cela signifie que Kubernetes peut servir le trafic √† partir de l‚Äôancienne version pendant l‚Äôinitialisation de la nouvelle, garantissant qu‚Äôaucune requ√™te n‚Äôest perdue.
- **V√©rifications de sant√©** (health checks) et sondes de disponibilit√© (readiness probes) : Kubernetes poss√®de des health checks qui emp√™chent le trafic d‚Äôatteindre les conteneurs tant qu‚Äôils ne sont pas totalement pr√™ts. Donc seules les instances op√©rationnelles servent les requ√™tes lors d‚Äôun d√©ploiement => pas de temps d'arr√™t.
- **Routage du trafic** : Dans Kubernetes, la couche Service g√®re le routage du trafic. Lors d‚Äôun d√©ploiement, Kubernetes contr√¥le quelles instances de Pods re√ßoivent le trafic, permettant une transition fluide entre les versions.

### Rolling Updates - Mises √† jour progressives

Au lieu de tout mettre √† jour d'un coup, Kubernetes met √† jour les pods un par un (ou par petit groupe)
et l'application reste disponible pendant la mise √† jour

Imaginons que vous avez 4 pods de version v1. Vous voulez passer √† la version v2

Kubernetes va :

1. Cr√©er 1 nouveau pod v2
2. Attendre qu'il soit pr√™t
3. Supprimer 1 ancien pod v1
4. R√©p√©ter jusqu'√† ce que tous les pods soient en v2

Avantages :

- Z√©ro temps d'arr√™t
- Possibilit√© de revenir en arri√®re en cas de probl√®me
- et Contr√¥le du rythme de mise √† jour


![Rolling updates](./../../img/kubernetes-rolling-updates.png)


> En r√©sum√©, l‚Äôarchitecture Kubernetes garantit z√©ro temps d'arr√™t en maintenant les instances actives et en routant le trafic intelligemment, alors que les d√©ploiements avec des configurations Docker basiques manquent de ces m√©canismes int√©gr√©s, entra√Ænant souvent de courts temps d'arr√™t lors des mises √† jour.

![Dilbert on Kubernetes](./../../img/dilbert-kubernetes.png)


## Structure de base d'un cluster Kubernetes



![Overview of Kubernetes structure](./../../img/kubernetes-overview.png)
By Khtan66 - Own work, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=53571935

Voir aussi:

![Overview of Kubernetes structure](./../../img/kubernetes_architecture_overview.webp)
https://medium.com/devops-mojo/kubernetes-architecture-overview-introduction-to-k8s-architecture-and-understanding-k8s-cluster-components-90e11eb34ccd

et

![Kubernetes Overview](./../../img/kubernetes_architecture_overview-02.png)


Les elements d'un cluster Kubernetes  sont : **pods**, **worker nodes** et **plane control**

- Le master (plane control), qui est la tour de contr√¥le, il est compos√© d‚Äôun ou plusieurs noeuds / nodes.
- Les workers nodes, qui h√©bergent les Pods.
- Les Pods sont constitu√©s de conteneurs.

### **Nodes**

Un noeud peut √™tre une machine virtuelle ou une machine physique. Chaque noeud contient les services n√©cessaires √† l‚Äôex√©cution des pods et est g√©r√© par le ou les masters.

Chaque noeud (master ou worker) ex√©cute :

- un runtime container (comme Docker) `containerd`
- `Kubelet` (agent qui g√®re le node)
- `Kube-proxy` (proxy r√©seau)

> Un runtime comme `containerd` manage le cycle de vie des containers: cr√©ation,  d√©marrage, arr√™t et suppression des containers, ainsi que la gestion des op√©rations de bas niveau n√©cessaires pour les ex√©cuter.

Pensez-y comme un restaurant :

* Master Node = chef du restaurant (qui prend les d√©cisions)
* Worker Nodes = Personnel de cuisine (qui fait le vrai travail)

Quand on dit "node" sans pr√©cision, on parle g√©n√©ralement d'un "worker node"

### plane control (master node)

Le r√¥le du master est de piloter le fonctionnement du cluster Kubernetes.

Il ex√©cute un serveur d‚ÄôAPI, un scheduler, divers contr√¥leurs et un syst√®me de stockage pour conserver l‚Äô√©tat du cluster et la configuration r√©seau.

```bash
Master Node
‚îú‚îÄ‚îÄ Container Runtime (containerd)
‚îÇ   ‚îî‚îÄ‚îÄ Runs control plane containers:
‚îÇ       ‚îú‚îÄ‚îÄ kube-apiserver
‚îÇ       ‚îú‚îÄ‚îÄ kube-scheduler
‚îÇ       ‚îú‚îÄ‚îÄ kube-controller-manager
‚îÇ       ‚îî‚îÄ‚îÄ etcd
‚îú‚îÄ‚îÄ kubelet
‚îÇ   ‚îî‚îÄ‚îÄ Manages these control plane containers
‚îî‚îÄ‚îÄ kube-proxy
    ‚îî‚îÄ‚îÄ Handles networking rules
```

Le Master Node (Plan de Contr√¥le) :

* Agit comme le cerveau du cluster
* Prend les d√©cisions globales concernant le cluster
* G√®re la planification (scheduling)
* D√©tecte et r√©pond aux √©v√©nements du cluster



### Workers node

Les workers de Kubernetes sont les noeuds en charge de l‚Äôex√©cution des applications


```bash
Kubernetes Cluster
‚îú‚îÄ‚îÄ Master Node (Control Plane)
‚îÇ   ‚îú‚îÄ‚îÄ API Server
‚îÇ   ‚îú‚îÄ‚îÄ Scheduler
‚îÇ   ‚îú‚îÄ‚îÄ Controller Manager
‚îÇ   ‚îî‚îÄ‚îÄ etcd
‚îî‚îÄ‚îÄ Worker Nodes
    ‚îú‚îÄ‚îÄ kubelet
    ‚îú‚îÄ‚îÄ kube-proxy
    ‚îî‚îÄ‚îÄ Container Runtime (Docker/containerd)
```

Un Worker Node :

- Ex√©cute les applications r√©elles (pods)
- Effectue la charge de travail r√©elle
- Fait des rapports au master node
- Peut √™tre ajout√©/supprim√© selon les besoins



### **Pods** (Pensez : Docker containers+)

Un Pod est la plus petite unit√© d√©ployable dans Kubernetes.

Un Pod :

- Peut contenir un ou plusieurs conteneurs
- Les conteneurs dans un Pod partagent :
  - M√™me adresse IP
  - M√™me espace de stockage
  - M√™me cycle de vie

Voici un exemple simple d'un Pod :

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: mon-application
spec:
  containers:
  - name: app-container
    image: nginx:latest
    ports:
    - containerPort: 80
```

Un pod est :

- √âph√©m√®re (peut √™tre d√©truit/recr√©√© √† tout moment)
- Toujours programm√© sur un seul Node
- Obtient une IP unique dans le cluster
- Peut mourir et √™tre remplac√© (nouvelle IP)

Un Pod est comme une √©quipe de travail dans un bureau partag√© (node) o√π plusieurs personnes (containers) travaillent ensemble

Pensez-y comme  :

- L'√©quipe (Pod) travaille toujours au m√™me endroit
- Les membres de l'√©quipe (conteneurs) partagent les m√™mes ressources
- Si l'√©quipe change de bureau, elle reste ensemble

Par exemple :

- Application web + cache
- Application + collecteur de logs
- Application principale + conteneur auxiliaire (sidecar)

#### Replicas

Un Replica est une copie identique d'un Pod qui permet d'avoir plusieurs instances d'une m√™me application

Les Replicas sont G√©r√©s par un `ReplicaSet` ou un `Deployment`

1. Exemple de configuration :
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mon-app
spec:
  replicas: 3    # Ici on demande 3 copies identiques
  selector:
    matchLabels:
      app: mon-app
  template:
    metadata:
      labels:
        app: mon-app
    spec:
      containers:
      - name: nginx
        image: nginx:latest
```

Avantages des Replicas :

- Haute disponibilit√©
- R√©partition de charge
- Tol√©rance aux pannes
- Mise √† l'√©chelle facile

1. Commandes utiles :

```bash
# Modifier le nombre de replicas
kubectl scale deployment mon-app --replicas=5

# Voir l'√©tat des replicas
kubectl get deployment mon-app

# Voir les pods (replicas) en cours d'ex√©cution
kubectl get pods
```

Sc√©narios d'utilisation :

- Trafic √©lev√© ‚Üí augmenter les replicas
- Maintenance ‚Üí garder le service actif
- Mise √† jour progressive ‚Üí remplacer les replicas un par un
- √âconomie de ressources ‚Üí r√©duire les replicas la nuit



#### outils utilis√©s par un pod

Les pods dans Kubernetes utilisent plusieurs outils essentiels.

- Runtime Container : `containerd` (le plus courant aujourd'hui) (historiquement  Docker), ou CRI-O, podman qui g√®re:
  - L'ex√©cution des conteneurs
  - La gestion des images
  - L'isolation des ressources

- Outils de Networking qui g√®rent :
  - La communication entre pods
  - L'attribution des IPs
  - Les r√®gles de r√©seau

```
‚îú‚îÄ‚îÄ CNI (Container Network Interface)
‚îÇ   ‚îú‚îÄ‚îÄ Calico
‚îÇ   ‚îú‚îÄ‚îÄ Flannel
‚îÇ   ‚îú‚îÄ‚îÄ Weave
‚îÇ   ‚îî‚îÄ‚îÄ Cilium
```

- Outils de gestion de Stockage

```
‚îú‚îÄ‚îÄ CSI (Container Storage Interface)
‚îÇ   ‚îú‚îÄ‚îÄ AWS EBS
‚îÇ   ‚îú‚îÄ‚îÄ Azure Disk
‚îÇ   ‚îú‚îÄ‚îÄ GCE PD
‚îÇ   ‚îî‚îÄ‚îÄ Local Storage
```

- Outils de Surveillance :
  - cAdvisor : metriques des conteneurs
  - Liveness probes : v√©rification sant√©
  - Readiness probes : v√©rification disponibilit√©
  - Startup probes : v√©rification d√©marrage

Un exemple de configuration :

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: mon-pod
spec:
  containers:
  - name: app
    image: nginx
    livenessProbe:
      httpGet:
        path: /health
        port: 80
    volumeMounts:
    - name: data
      mountPath: /data
  volumes:
  - name: data
    persistentVolumeClaim:
      claimName: mon-pvc
```

- Outils de Logging :
  - stdout/stderr
  - Fluentd
  - Logrotate
  - Journald

Pensez-y comme une maison üè° :

- Runtime : Syst√®me √©lectrique üîå
- Network : Plomberie üö∞
- Storage : Rangements üõçÔ∏è
- Monitoring : Alarmes et capteurs üå°Ô∏è

### **Deployments** (Pensez : Docker Compose services, mais plus puissant)

- D√©finit combien de r√©pliques de votre pod doivent s'ex√©cuter.
- G√®re les mises √† jour et les rollbacks.
- Auto-r√©paration : red√©marre automatiquement les pods en √©chec.

Un Deployment est un objet qui g√®re des `ReplicaSet` pour

- d√©ployer et mettre √† jour des applications
- G√®rer automatiquement les pods
- Garantir la disponibilit√© de l'application

1. Structure basique :
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mon-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: mon-app
  template:
    metadata:
      labels:
        app: mon-app
    spec:
      containers:
      - name: mon-container
        image: nginx:1.19
```

Les fonctionnalit√©s  principales du module de deploiement sont :

- Scaling (mise √† l'√©chelle)
  * `kubectl scale deployment mon-app --replicas=5`
- Rolling Updates (mises √† jour progressives)
- Rollback (retour arri√®re)
  * `kubectl rollout undo deployment/mon-app`
- Auto-r√©paration


On peut definir une strat√©gie de mise √† jour avec

```yaml
spec:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1        # Pods suppl√©mentaires max
      maxUnavailable: 1  # Pods indisponibles max
```

Par analogie, pensez √† une √©quipe de serveurs dans un restaurant :

- Le Deployment est le manager
- Les ReplicaSets sont les √©quipes
- Les Pods sont les serveurs individuels
- Si un serveur est malade (pod crash), il est remplac√©
- Pendant les heures de pointe, on peut ajouter plus de serveurs (scaling)

Quelques commandes utiles :

```bash
# Cr√©er un deployment
kubectl create deployment mon-app --image=nginx

# Voir le statut
kubectl get deployment

# Voir l'historique
kubectl rollout history deployment/mon-app

# Mettre √† jour l'image
kubectl set image deployment/mon-app nginx=nginx:1.20
```


### **Services** (Pensez : Docker Compose network settings)

Un Service d√©finit un ensemble logique de pods

- Fournit un point d'acc√®s r√©seau stable (IP stable & nom de domaine DNS `mon-service.namespace.svc.cluster.local`)
- Agit comme un √©quilibreur de charge / load balancer
- Permet la communication entre les pods


Il y a diff√©rents types de services:

- **ClusterIP** (par d√©faut): Acc√®s interne au cluster uniquement
- **NodePort**: Expose le service sur l'IP de chaque Node
- **LoadBalancer**: Expose le service √† l'ext√©rieur et utilise le load balancer du cloud provider
- **ExternalName**: Mappe le service vers un nom DNS externe


Exemple simple de d√©claration de service :

```yaml
apiVersion: v1
kind: Service
metadata:
  name: mon-service
spec:
  type: ClusterIP
  selector:
    app: mon-app
  ports:
    - protocol: TCP
      port: 80        # Port du Service
      targetPort: 8080 # Port du Pod
```

- D√©couverte de services


Par analogies pensez √† un service comme √† l'accueil d'une entreprise :

- Les visiteurs (requ√™tes) passent par l'accueil (Service)
- L'accueil les dirige vers les employ√©s disponibles (Pods)
- Si un employ√© change de bureau (Pod red√©marre), l'accueil sait toujours comment le joindre


### D√©couverte de services / Service Discovery

Les Pods (conteneurs) dans Kubernetes peuvent appara√Ætre et dispara√Ætre et leurs adresses IP peuvent aussi changer

Mais les applications ont besoin d'un moyen fiable pour se trouver et communiquer entre elles

La D√©couverte de Services (Service Discovery) dans Kubernetes fonctionne comme un annuaire  / mapping

- Kubernetes attribue un nom fixe √† chaque Service
- Les applications peuvent utiliser ce nom au lieu de m√©moriser des adresses IP
- Kubernetes maintient automatiquement la liste des pods en bon √©tat derri√®re chaque service

Voici un exemple simple :

```yaml
# Un service nomm√© 'database'
apiVersion: v1
kind: Service
metadata:
  name: database
spec:
  selector:
    app: mysql
  ports:
    - port: 3306
```

Quand d'autres applications veulent se connecter √† la base de donn√©es, elles utilisent simplement :

```bash
database.default.svc.cluster.local
```

ou simplement `database` dans le m√™me `namespace`.

Pensez-y comme √† une commande de pizza üçïüçïüçï :

- Vous n'avez pas besoin de conna√Ætre le num√©ro de t√©l√©phone üì≤ du livreur sp√©cifique üõµ
- Vous avez juste besoin du nom de la pizzeria
- La pizzeria s'occupe de trouver un livreur disponible
- De la m√™me fa√ßon, Kubernetes s'occupe de trouver le bon **pod** pour votre requ√™te



###  **Volumes** (Pensez : Docker volumes)

- Similaires aux Docker volumes mais avec plus d'options.
- Peuvent √™tre √©ph√©m√®res ou persistants.
- Plusieurs backends de stockage support√©s.

### **Namespaces**

- Moyen d‚Äôorganiser les ressources.
- Comme avoir plusieurs projets Docker Compose.
- Fournit une isolation entre les √©quipes/projets.

## Le manifest

Dans Kubernetes, le fichier **manifest** est le document de configuration qui d√©finit l‚Äô√©tat souhait√© d'une application et la charge de travail (workload).

### **Configuration D√©clarative**

Kubernetes suit un **mod√®le d√©claratif** : on d√©crit l‚Äô√©tat souhait√© dans un manifest, et Kubernetes s‚Äôoccupe d‚Äôatteindre cet √©tat. C'est la m√™me logique pour [Terraform](https://www.terraform.io/) : Infrastructure as Code (IaC)

Le **manifest** sp√©cifie les ressources: Pods, Deployments, Services, ConfigMaps, Volume, et leurs param√®tres ainsi que les strat√©gies employ√©es. c'est un fichier yaml =>  contr√¥le de version avec Git

- **Gestion des Ressources** : Les manifests d√©finissent les ressources Kubernetes
  - **Pods** : Groupes de conteneurs.
  - **Deployments** : Gestion et scaling des Pods.
  - **Services** : Configuration de l‚Äôacc√®s r√©seau.
- **ConfigMaps et Secrets** : Stockage s√©curis√© de configurations et informations sensibles.

En d√©finissant ces ressources, le manifest facilite la gestion compl√®te du cycle de vie de l'application : scaling, mises √† jour, et self-healing.

- **Contr√¥le de Version** : fichiers en YAML ou JSON, contr√¥le de version avec Git
  - coh√©rence de la configuration entre diff√©rents environnements (d√©veloppement, staging, production).
  - rollback, blame, etc

- **Portabilit√©, Automatisation**: Les manifests rendent les applications portables et d√©ployables sur diff√©rents clusters Kubernetes. automatisation dans des pipelines CI/CD, pour d√©ployer automatiquement des applications apr√®s chaque modification.

Kubernetes utilise le manifest pour comprendre **l'√©tat souhait√©** (desired state) de l‚Äôapplication (nombre de r√©plicas, versions des images, allocations de ressources, etc.). Le **Kubernetes Controller** surveille le cluster pour garantir que l‚Äô√©tat en cours correspond √† celui qui est d√©fini dans le manifest. Si des √©carts se produisent (ex. crash de Pods), Kubernetes prend des mesures correctives. => self-healing


### Exemple de fichier Manifest

Exemple de manifest pour un Deployment Kubernetes :

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
```

Ce fichier d√©finit un d√©ploiement  `nginx-deployment`, avec trois `replicas` d‚Äôun conteneur `nginx` exposant le port 80.

Une **replica** d√©signe le nombre d'instances (copies) d'un Pod que l'on souhaite faire fonctionner √† un moment donn√©. Cela est particuli√®rement utile pour garantir une haute disponibilit√© et une tol√©rance aux pannes de l'application.

Les manifests sont fondamentaux dans Kubernetes.

- Ils agissent comme des plans pour d√©ployer, g√©rer et scaler les ressources dans un cluster.
- Ils permettent une gestion d√©clarative de l'infrastructure, soutiennent l'automatisation, facilitent la collaboration via le contr√¥le de version
- Ils aident Kubernetes √† maintenir l‚Äô√©tat souhait√© des applications.


## Conclusion et suite

Avant de passer a la suite et la mise en pratique, 2 questions primordiales

- pourquoi l'appli [Borg](https://research.google/pubs/large-scale-cluster-management-at-google-with-borg/) est un [cube](https://headhuntersholosuite.fandom.com/wiki/Borg_Cube) ?
- pourquoi 7 branches dans la roue ? [7 of 9](https://screenrant.com/seven-of-nine-star-trek-worst-things-happened/)

Quelques resources:

- Une explication en comics de Kubernetes : <https://cloud.google.com/kubernetes-engine/kubernetes-comic>
- Une terminologie : <https://wiki.sfeir.com/kubernetes/terminologie/>
- Une liste de tuto : <https://wiki.sfeir.com/kubernetes/tutorial_kubernetes/>
